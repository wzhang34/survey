\section{Preliminary}
\label{sec:funda}

In this section, we first review basic building blocks of deep learning layer-wisely in Section~\ref{ssec:layers}, and then discuss several widely adopted network architectures in Section~\ref{ssec:architecture}.

\subsection{Building blocks}
\label{ssec:layers}

Most popular deep learning frameworks are highly modularize, such that deep networks can be easily constructed by a collection of interacting layers. 

\textbf{Convolution layer} \cite{NIPS2012_4824} applies the convolution operation over an input signal, which is especially critical for multimedia visual data. 
%In most cases, \emph{stride} and \emph{padding} are adopted to adapt different input/output sizes. 
Transposed convolution\footnote{In some literatures, it is also referred as fractionally-strided convolution or deconvolution.} goes in the opposite direction \cite{arXiv:1603.07285}, and is widely adopted for upsampling in deblurring \cite{su2016deep}, image matting \cite{deepmatting}, super resolution \cite{arXiv:1704.03915}, image generation \cite{dcgan} and restoration \cite{NIPS2016}.
%A convolution can be written as a product with sparse projection matrix $\mathbf{P}$ , while transposed convolution defined by $\mathbf{P}^T$ is widely adopted for upsampling, e.g., deblur \cite{su2016deep}, matting \cite{deepmatting}, super resolution \cite{}, image generation \cite{dcgan} and restoration \cite{NIPS2016}.

%One can transform something that has the shape of the output of some convolution to something that has the shape of its input, while maintaining a connectivity pattern that is compatible with convolution.

\textbf{Fully connected layer} \cite{Rumelhart:1986:LIR:104279.104293} defines a linear transformation between layers, where neurons in one layer is connected to all neurons in another layer. A typical functionality is high-level reasoning \cite{NIPS2012_4824} after several convolution layers. 


\textbf{Activation} \cite{Han1995,Hahnloser2000DigitalSA,Nair:2010:RLU:3104322.3104425,Maas13rectifiernonlinearities,journals/corr/ClevertUH15} and \textbf{Pooling layers} \cite{NIPS2012_4824,Scherer:2010:EPO:1886436.1886447} introduce nonlinearity into networks, which have demonstrated their superior performance in multimedia analytics.
%Traditional \textbf{Sigmoid} is best known for its continuity, recent \textbf{Relu}, \textbf{Noisy ReLU} \cite{Hinton_rectifiedlinear} \textbf{Leaky Relu} \cite{Maas13rectifiernonlinearities}, \textbf{ELU} \cite{journals/corr/ClevertUH15} are all derived from the rectified linear unit function. 
%
In principle, activation defines the response mechanism for neuron outputs, and pooling combine multiple outputs at one layer into a single output in the next layer, which introduces a form of non-linear down-sampling.


\textbf{Normalization layers} \cite{icml2015_ioffe15,Ulyanov2016InstanceNT} are critical in stabilizing the training process and accelerating the convergence speed. For example, Batch Normalization \cite{icml2015_ioffe15} reduces internal covariate shift in neural networks, which leads to faster convergence. 
%Recent \textbf{Instance Normalization} \cite{} suits better for stylization tasks. 


\textbf{Loss layers} define various loss functions for diverse purposes, ranging from \emph{L1}, \emph{MSE}, \emph{Cross Entropy}, \emph{Negative log likelihood} losses to \emph{KL-divergence} and \emph{Triplet Margin} losses. 


%Dropout layer: 

%Sparse layer: 

% initializaiton


% optimization

Optimizing deep networks is generally difficult. On one hand, different initializations \cite{GlorotAISTATS2010,He:2015:DDR:2919332.2919814} have major impact on network convergence. On the other hand, the optimization algorithm is also important for convergence. The fundamental optimization technique is based on back-propagation \cite{Rumelhart:1988:LRB:65669.104451} via SGD \cite{Saad:1999:OLN:304710,Polyak:1992:ASA:131092.131098}, Adam \cite{Kingma2014AdamAM}, LBFGS, Rprop, or RMSprop \cite{journals/corr/Graves13}.



\subsection{Network Architectures}
\label{ssec:architecture}

\subsubsection{Convolutional Neural Networks (CNN)} \hfill 

Convolutional neural network is first introduced decades ago \cite{LeCun:1989:BAH:1351079.1351090} for recognizing zip codes, which is rather primitive at that time. Recent advancements in computation hardware (GPU\footnote{Graphics Processing Unit}) and abundant training data \cite{ILSVRC15} bring prosperity to CNN architecture \cite{NIPS2012_4824}.




%deep CNNs have recently shown an explosive popularity
%partially due to its success in image classification [18], [25].
%They have also been successfully applied to other fields, such as object detection [33], [50], face recognition
%[38], and pedestrian detection [34]. Several factors are of central importance in this progress: (i) the efficient training implementation on modern powerful GPUs [25], (ii) the proposal of the rectified linear unit (ReLU) [32] which makes convergence much faster while still presents good quality [25], and (iii) the easy access to an abundance of data (like ImageNet [9]) for training larger models. 

...


\subsubsection{Recurrent Neural Networks (RNN)} \hfill 

Besides the feed-forward network architecture, another big branch is based on the recurrent structures \emph{RNN}. However, RNN suffers from the vanishing \& exploding gradient problem since it was invented. \textbf{LSTM} captures the long-term dependencies with the cell state. \textbf{GRU} further combines the forget and input gates into an update gate, and mergers the cell state and hidden state. 

...

\subsubsection{Generative Adversarial Networks}\hfill 

Generative Adversarial Networks (GAN) \cite{gan} gains great attention since it only defines the high-level objective (real/fake) rather than a fixed loss function. 


In a short time period, many variants, e.g., wGAN\cite{wgan}, DCGAN\cite{dcgan}, have improved the original framework for generating more realistic images robustly.
%
Laplacian Pyramid of Adversarial Networks \cite{lapgan} extends GAN for progressively generating images with higher resolution. More recent work by NVIDIA \cite{nvidia_celebrity} futher generates celebrity photos in impressive quality. 
%
Conditional GAN \cite{cgan} takes extra input for generating images based on a constraint.
%
Pix2pix \cite{pix2pix} translates an image to another representation with conditional GAN. 
CycleGAN \cite{CycleGAN2017}, DiscoGan \cite{Kim2017LearningTD} and DualGan \cite{Yi2017DualGANUD} share the same idea for image translation between different domains, where unpaired data is adopt in a self-supervised way. 
%
Moreover, conditional GAN is also applied for generating images conditioning on text descriptions \cite{icml16,stackgan,auxgan} of bird \cite{cub} or flower \cite{flower}.

%Recent advancements in deep learning, especially generative adversarial networks (GAN), have shown great potential in bridging the gap between different image representations. Isola \cite{pix2pix} proposes an image-to-image translation technique using paired training data, which can model a wide range of tasks, e.g., ``sketch$\leftrightarrow$photos" and ``labels$\leftrightarrow$street scenes", in a unified architecture. 




